import streamlit as st
import torch
import torchvision.models as models
from torchvision import transforms
from PIL import Image

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="Brain Tumor Classification", page_icon="üß†")
st.title("üß† Brain Tumor Classification Web App")
st.write("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û MRI ‡∏™‡∏°‡∏≠‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏á‡∏≠‡∏Å 4 ‡∏Ñ‡∏•‡∏≤‡∏™ ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• MobileNetV3")

# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• MobileNetV3
@st.cache_resource
def load_model():
    # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• MobileNetV3 Large
    model = models.mobilenet_v3_large(weights=None)
    # ‡∏õ‡∏£‡∏±‡∏ö Layer ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å 4 ‡∏Ñ‡∏•‡∏≤‡∏™ (glioma, meningioma, notumor, pituitary)
    model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, 4)
    
    # ‡πÇ‡∏´‡∏•‡∏î Weights ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤ (‡πÉ‡∏ä‡πâ CPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö‡∏ü‡∏£‡∏µ)
    checkpoint = torch.load('mobilenetv3_checkpoint_fold2.pt', map_location=torch.device('cpu'), weights_only=False)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
        
    model.eval()
    return model

model = load_model()

# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™
class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']

# 4. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û (Transform)
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 5. UI ‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û MRI ‡∏™‡∏°‡∏≠‡∏á...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î', use_column_width=True)
    st.write("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
    img_tensor = transform(image).unsqueeze(0)
    
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
    with torch.no_grad():
        outputs = model(img_tensor)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
        confidence, predicted = torch.max(probabilities, 0)
        
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    predicted_class = class_names[predicted.item()]
    st.success(f"**‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:** {predicted_class}")
    st.info(f"**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (Confidence):** {confidence.item() * 100:.2f}%")
